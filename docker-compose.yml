# SolanaSniperV3 - Docker Compose Configuration
# Optimized for Contabo VDS: 6 CPU / 24GB RAM
version: '3.8'

services:
  # ===== SNIPER-CORE (RUST) - HIGH PRIORITY CPU =====
  sniper-core:
    build: 
      context: ./sniper-core
      dockerfile: Dockerfile
    container_name: sniper-core
    ports:
      - "8003:8003"
    environment:
      # Tokio configuration for Contabo VDS
      - TOKIO_WORKER_THREADS=4
      - RUST_LOG=sniper_core=info,tower_http=debug
      
      # Trading configuration
      - SNIPER_TRADING_MODE=paper
      
      # Solana & Helius configuration
      - SNIPER_SOLANA_RPC_URL=${SNIPER_SOLANA_RPC_URL}
      - SNIPER_HELIUS_API_KEY=${SNIPER_HELIUS_API_KEY}
      - SNIPER_WALLET_PRIVATE_KEY=${SNIPER_WALLET_PRIVATE_KEY}
      
      # Internal services
      - SNIPER_REDIS_URL=redis://dragonfly:6379
      - SNIPER_DATABASE_URL=postgresql://sniper:${DB_PASSWORD}@postgresql:5432/sniper
      
      # Performance tuning
      - SNIPER_MAX_CONNECTIONS=1000
      - SNIPER_REQUEST_TIMEOUT_MS=5000
      - SNIPER_RETRY_ATTEMPTS=3
      
      # Risk management
      - SNIPER_MAX_POSITION_SIZE=1000.0
      - SNIPER_MAX_DAILY_LOSS=500.0
      - SNIPER_MAX_SLIPPAGE=0.05
    depends_on:
      - dragonfly
      - postgresql
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4.0'        # 4 out of 6 available cores
          memory: 6G         # 25% of total RAM
        reservations:
          cpus: '3.0'        # Guaranteed minimum
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - sniper-network

  # ===== DRAGONFLYDB - HIGH PRIORITY RAM =====
  dragonfly:
    image: docker.dragonflydb.io/dragonflydb/dragonfly:latest
    container_name: dragonfly-cache
    ports:
      - "6379:6379"
    command: [
      "dragonfly",
      "--logtostderr",
      "--maxmemory=10gb",      # 40% of total RAM for cache
      "--threads=6",           # Use all available cores
      "--proactor_threads=4",  # Optimized for Contabo
      "--cache_mode=true"
    ]
    volumes:
      - dragonfly_data:/data
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 12G          # 50% of total RAM
        reservations:
          memory: 8G           # Guaranteed minimum
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - sniper-network

  # ===== POSTGRESQL - MODERATE PRIORITY =====
  postgresql:
    image: postgres:15-alpine
    container_name: postgresql-db
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=sniper
      - POSTGRES_USER=sniper
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - postgresql_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sniper -d sniper"]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - sniper-network

  # ===== STRATEGY-HOST (PYTHON) - PLACEHOLDER =====
  # TODO: Implement when Python service is ready
  # strategy-host:
  #   build: 
  #     context: ./strategy-host
  #     dockerfile: Dockerfile
  #   container_name: strategy-host
  #   ports:
  #     - "8001:8001"
  #   environment:
  #     - PYTHONPATH=/app
  #     - SNIPER_CORE_URL=http://sniper-core:8003
  #   depends_on:
  #     - sniper-core
  #     - dragonfly
  #     - postgresql
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '2.0'
  #         memory: 4G
  #   networks:
  #     - sniper-network

  # ===== KESTRA (WORKFLOW ORCHESTRATION) =====
  kestra:
    image: kestra/kestra:latest
    container_name: kestra-orchestrator
    ports:
      - "8080:8080"
    environment:
      - KESTRA_CONFIGURATION_PATH=/app/kestra.yml
    volumes:
      - kestra_data:/app/storage
      - ./kestra/kestra.yml:/app/kestra.yml:ro
      - ./kestra/flows:/app/flows:ro
      - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          memory: 1G
    depends_on:
      - postgresql
    networks:
      - sniper-network

  # ===== MONITORING (OPTIONAL) =====
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus-monitoring
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
    networks:
      - sniper-network
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana-dashboard
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
    depends_on:
      - prometheus
    networks:
      - sniper-network
    profiles:
      - monitoring

# ===== NETWORKS =====
networks:
  sniper-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# ===== VOLUMES =====
volumes:
  dragonfly_data:
    driver: local
  postgresql_data:
    driver: local
  kestra_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# ===== RESOURCE SUMMARY FOR CONTABO VDS =====
# Total CPU allocation: 4 + 1 + 1 + 1 + 0.5 + 0.5 = 8 cores (with overcommit)
# Total RAM allocation: 6 + 12 + 2 + 2 + 1 + 1 = 24GB (exactly matches Contabo)
# 
# Priority allocation:
# 1. sniper-core: 4 CPU + 6GB RAM (critical path)
# 2. dragonfly: 6 CPU + 12GB RAM (shared, high-performance cache)
# 3. Others: remaining resources
#
# Note: CPU overcommit is acceptable as not all services will use 100% simultaneously
